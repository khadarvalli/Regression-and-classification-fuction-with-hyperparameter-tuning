{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75011ab7",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cc389a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,r2_score,mean_absolute_error\n",
    "\n",
    "def training(X_train,X_test,y_train,y_test):\n",
    "#LinearRegression\n",
    "    try:\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        logmodel=LinearRegression()\n",
    "        logmodel.fit(X_train,y_train)\n",
    "        pred=logmodel.predict(X_test)\n",
    "        # Find Accuracy using accuracy_score method\n",
    "        logmodel_accuracy = mean_squared_error(y_test, pred)\n",
    "        #mean_absolute_error\n",
    "        logmodel_auc = mean_absolute_error(y_test, pred)\n",
    "        #r2_score\n",
    "        logmodel_F1_Score =r2_score(y_test, pred)\n",
    "    except:\n",
    "        print('error in LinearRegression')\n",
    "#SGDClassifier\n",
    "    try:\n",
    "        from sklearn.linear_model import SGDRegressor\n",
    "        sgd =  SGDRegressor()\n",
    "        sgd.fit(X_train,y_train)\n",
    "        pred=sgd.predict(X_test)\n",
    "        # Find Accuracy using accuracy_score method\n",
    "        sgd_accuracy = mean_squared_error(y_test, pred) \n",
    "        # F1 Score\n",
    "        sgd_F1_Score =r2_score(y_test, pred)\n",
    "        # Area Under Curve\n",
    "        sgd_auc = mean_absolute_error(y_test,pred)\n",
    "    except:\n",
    "        print('error in SGDRegressor')\n",
    "\n",
    "#DecisionTreeClassifier.\n",
    "    try:\n",
    "        from sklearn.tree import DecisionTreeRegressor\n",
    "        dt=DecisionTreeRegressor(random_state=1)\n",
    "        dt.fit(X_train,y_train)\n",
    "        pred=dt.predict(X_test)\n",
    "        # Find Accuracy using accuracy_score method\n",
    "        dt_accuracy =mean_squared_error(y_test, pred)\n",
    "        # F1 Score\n",
    "        dt_F1_Score =r2_score(y_test, pred)\n",
    "        # Area Under Curve\n",
    "        dt_auc = mean_absolute_error(y_test,pred)\n",
    "    except:\n",
    "        print('error in DecisionTreeRegressor')    \n",
    "#RandomForestClassifier.\n",
    "    try:\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        rf=RandomForestRegressor()\n",
    "        rf=rf.fit(X_train,y_train)\n",
    "        pred=rf.predict(X_test)\n",
    "        # Find Accuracy using accuracy_score method\n",
    "        rf_accuracy = mean_squared_error(y_test, pred)\n",
    "        # F1 Score\n",
    "        rf_F1_Score =r2_score(y_test, pred)\n",
    "        # Area Under Curve\n",
    "        rf_auc = mean_absolute_error(y_test,pred)\n",
    "    except:\n",
    "        print('error in RandomForestRegressor')    \n",
    "#AdaBoostRegressor\n",
    "    try:\n",
    "        from sklearn.ensemble import AdaBoostRegressor\n",
    "        nb=AdaBoostRegressor()\n",
    "        nb.fit(X_train,y_train)\n",
    "        pred=nb.predict(X_test)\n",
    "        # Find Accuracy using accuracy_score method\n",
    "        nb_accuracy =mean_squared_error(y_test, pred)\n",
    "        # F1 Score\n",
    "        nb_F1_Score =r2_score(y_test, pred)\n",
    "        # Area Under Curve\n",
    "        nb_auc = mean_absolute_error(y_test,pred)\n",
    "    except:\n",
    "        print('error in AdaBoostRegressor')    \n",
    "#GradientBoostingRegressor\n",
    "    try:\n",
    "        from sklearn.ensemble import GradientBoostingRegressor\n",
    "        gb=GradientBoostingRegressor()\n",
    "        gb.fit(X_train,y_train)\n",
    "        pred=gb.predict(X_test)\n",
    "        # Find Accuracy using accuracy_score method\n",
    "        gb_accuracy =mean_squared_error(y_test, pred)\n",
    "        # F1 Score\n",
    "        gb_F1_Score =r2_score(y_test, pred)\n",
    "        # Area Under Curve\n",
    "        gb_auc = mean_absolute_error(y_test,pred)\n",
    "    except:\n",
    "        print('error in GradientBoostingRegressor')    \n",
    "#KNeighborsClassifier\n",
    "    try:\n",
    "        from sklearn.neighbors import KNeighborsRegressor\n",
    "        knn=KNeighborsRegressor() #p=2 means euclidean distance\n",
    "        knn.fit(X_train,y_train)\n",
    "        pred=knn.predict(X_test)\n",
    "        # Find Accuracy using accuracy_score method\n",
    "        knn_accuracy = mean_squared_error(y_test, pred) \n",
    "        # F1 Score\n",
    "        knn_F1_Score =r2_score(y_test, pred)\n",
    "        # Area Under Curve\n",
    "        knn_auc = mean_absolute_error(y_test,pred)\n",
    "    except:\n",
    "        print('error in KNeighborsRegressor')\n",
    "#SVC\n",
    "#     try:\n",
    "#         from sklearn.svm import SVR\n",
    "#         SVC=SVR()\n",
    "#         SVC.fit(X_train,y_train)\n",
    "#         pred=SVC.predict(X_test)\n",
    "#         # Find Accuracy using accuracy_score method\n",
    "#         svc_accuracy = mean_squared_error(y_test, pred)\n",
    "#         # F1 Score\n",
    "#         svc_F1_Score =r2_score(y_test, pred)\n",
    "#         svc_auc = mean_absolute_error(y_test,pred)\n",
    "#     except:\n",
    "#         print('error in svr')\n",
    "\n",
    "\n",
    "#XGBClassifier\n",
    "    try:\n",
    "        from xgboost import XGBRegressor\n",
    "        xgb = XGBRegressor()\n",
    "        xgb.fit(X_train, y_train)\n",
    "        pred=xgb.predict(X_test)\n",
    "        # Find Accuracy using accuracy_score method\n",
    "        xgb_accuracy = mean_squared_error(y_test, pred) \n",
    "        # F1 Score\n",
    "        xgb_F1_Score =r2_score(y_test, pred)\n",
    "        # Area Under Curve\n",
    "        xgb_auc = mean_absolute_error(y_test,pred)\n",
    "    except:\n",
    "        print('error in XGBRegressor')    \n",
    "#CatBoostClassifier\n",
    "    try:\n",
    "        from catboost import CatBoostRegressor\n",
    "        cb = CatBoostRegressor()\n",
    "        cb.fit(X_train, y_train)\n",
    "        pred=cb.predict(X_test)\n",
    "        # Find Accuracy using accuracy_score method\n",
    "        cb_accuracy = mean_squared_error(y_test, pred) \n",
    "        # F1 Score\n",
    "        cb_F1_Score =r2_score(y_test, pred)\n",
    "        # Area Under Curve\n",
    "        cb_auc = mean_absolute_error(y_test,pred)\n",
    "    except:\n",
    "        print('error in CatBoostRegressor')    \n",
    "#LGBMClassifier\n",
    "    try:\n",
    "        from lightgbm import LGBMRegressor\n",
    "        lgbm = LGBMRegressor()\n",
    "        lgbm.fit(X_train, y_train)\n",
    "        pred=lgbm.predict(X_test)\n",
    "        # Find Accuracy using accuracy_score method\n",
    "        lgbm_accuracy = mean_squared_error(y_test, pred) \n",
    "        # F1 Score\n",
    "        lgbm_F1_Score =r2_score(y_test, pred)\n",
    "        # Area Under Curve\n",
    "        lgbm_auc = mean_absolute_error(y_test,pred)\n",
    "\n",
    "    except:\n",
    "        print('error in LGBMRegressor')\n",
    "#ExtraTreesClassifier\n",
    "#     try:\n",
    "#         from sklearn.ensemble import ExtraTreesClassifier\n",
    "#         n=ExtraTreesClassifier()\n",
    "#         n.fit(X_train,y_train)\n",
    "#         pred=n.predict(X_test)\n",
    "#         Find Accuracy using accuracy_score method\n",
    "#         n_accuracy =mean_squared_error(y_test, pred)\n",
    "#         F1 Score\n",
    "#         n_F1_Score =r2_score(y_test, pred)\n",
    "#         n_auc = mean_absolute_error(y_test,pred) \n",
    "\n",
    "#     except:\n",
    "#         print('error in ExtraTreesClassifier')    \n",
    "    \n",
    "    Model_Comparison = pd.DataFrame({\n",
    "    'Model': ['Linear Regression', 'K-Nearest Neighbor', 'Decision Tree', 'Random Forest','AdaBoostRegressor','SGDRegressoor','XGBClassifier','CatBoostClassifier','LGBMClassifier','GradientBoostingRegressor'],\n",
    "    'MSE': [logmodel_accuracy, knn_accuracy,dt_accuracy, rf_accuracy, nb_accuracy, sgd_accuracy, xgb_accuracy,cb_accuracy,lgbm_accuracy,gb_accuracy],\n",
    "    'MAE': [logmodel_auc, knn_auc, dt_auc, rf_auc, nb_auc, sgd_auc, xgb_auc,cb_auc,lgbm_auc,gb_auc],\n",
    "    'R2_score':[logmodel_F1_Score, knn_F1_Score, dt_F1_Score, rf_F1_Score, nb_F1_Score, sgd_F1_Score, xgb_F1_Score,cb_F1_Score,lgbm_F1_Score,gb_F1_Score]})\n",
    "\n",
    "    Model_Comparison_df = Model_Comparison.sort_values(by='R2_score', ascending=False)\n",
    "    Model_Comparison_df = Model_Comparison_df.set_index('Model')\n",
    "    print(Model_Comparison_df.reset_index())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3727a433",
   "metadata": {},
   "source": [
    "# Regression in the form of function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9877371",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,r2_score,mean_absolute_error, accuracy_score\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor,LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor,GradientBoostingRegressor,ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b5f3ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = [LinearRegression(), SGDRegressor(), DecisionTreeRegressor(), RandomForestRegressor(), AdaBoostRegressor(),GradientBoostingRegressor(),KNeighborsRegressor(), XGBRegressor(),CatBoostRegressor(), LGBMRegressor()]\n",
    "models = [LinearRegression(), SGDRegressor(), DecisionTreeRegressor()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e7d4d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "def training(models, X_train,X_test,y_train,y_test):\n",
    "    for mod in models:\n",
    "        try :\n",
    "            start = time.time()\n",
    "            mod.fit(X_train,y_train)\n",
    "            pred = mod.predict(X_test)\n",
    "            #metrics\n",
    "            mse = mean_squared_error(y_test, pred)\n",
    "            r2_Score = r2_score(y_test, pred)\n",
    "            mae = mean_absolute_error(y_test,pred)\n",
    "            rmse = np.sqrt(mse)\n",
    "\n",
    "            results.append({'Model':mod,\n",
    "                      'MSE':mse,\n",
    "                      'RMSE':rmse,\n",
    "                      'MAE':mae,\n",
    "                      'R2_score':r2_Score\n",
    "                       })\n",
    "            end = time.time()\n",
    "            print('for training' ,mod, 'is',round(end-start),'sec' )\n",
    "        except:\n",
    "            print('error in training',mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31f9a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training(all_models, X_train,X_test,y_train,y_test)\n",
    "pd.DataFrame(results).sort_values(by='R2_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27321a49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6aeb9ea8",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77022338",
   "metadata": {},
   "source": [
    "for multi-classification we need to use \"average='weighted'\" and Auc_score will not come we can visualise it by using \"yellowbrick\" libray\n",
    "code given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded5e868",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import ROCAUC\n",
    "\n",
    "classes_names = ['<1_lakhs','<10_lakhs','<50_lakhs','<1_cr','>1_cr']\n",
    "model_name = knn\n",
    "\n",
    "visualizer = ROCAUC(model_name, classes=classes_names)\n",
    "visualizer.fit(X_train, y_train)       \n",
    "visualizer.score(X_test, y_test)       \n",
    "visualizer.show()                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5010c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e128f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from   sklearn.metrics import confusion_matrix , classification_report, accuracy_score, roc_auc_score, plot_roc_curve,precision_score,recall_score,f1_score\n",
    "\n",
    "def training(X_train,X_test,y_train,y_test):\n",
    "#LogisticRegressionabs\n",
    "    try:\n",
    "\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        logmodel=LogisticRegression(random_state=0)\n",
    "        logmodel.fit(X_train,y_train)\n",
    "        pred=logmodel.predict(X_test)\n",
    "\n",
    "        # Find Accuracy using accuracy_score method\n",
    "        logmodel_accuracy = accuracy_score(y_test, pred)\n",
    "        #confusionmatrix=confusion_matrix(y_test,pred) \n",
    "        # Precison\n",
    "        Precision = precision_score(y_test, pred, average='weighted')\n",
    "        # Recall\n",
    "        Recall = recall_score(y_test, pred, average='weighted')\n",
    "        # F1 Score\n",
    "        logmodel_F1_Score =f1_score(y_test, pred, average='weighted')\n",
    "        # Area Under Curve\n",
    "        y_pred_prod = logmodel.predict_proba(X_test)\n",
    "        y_pred_prod = [x[1] for x in y_pred_prod]\n",
    "\n",
    "\n",
    "        # pred = np.argmax(pred, axis=0) \n",
    "        # y_test = np.argmax(y_test, axis=0) \n",
    "        # logmodel_auc = roc_auc_score(y_test,y_pred_prod,multi_class = 'ovr', average='weighted')\n",
    "    except:\n",
    "        print('error in logmodel')\n",
    "    \n",
    "#SGDClassifier\n",
    "    try:\n",
    "        from sklearn.linear_model import SGDClassifier\n",
    "        sgd =  SGDClassifier(loss='modified_huber', shuffle=True,random_state=101)\n",
    "        sgd.fit(X_train,y_train)\n",
    "        pred=sgd.predict(X_test)\n",
    "        # Find Accuracy using accuracy_score method\n",
    "        sgd_accuracy = accuracy_score(y_test, pred) \n",
    "        # Precison\n",
    "        Precision = precision_score(y_test, pred, average='weighted')\n",
    "        # Recall\n",
    "        Recall = recall_score(y_test, pred, average='weighted')\n",
    "        # F1 Score\n",
    "        sgd_F1_Score =f1_score(y_test, pred, average='weighted')\n",
    "        # Area Under Curve\n",
    "#         y_pred_prod = sgd.predict_proba(X_test)\n",
    "#         y_pred_prod = [x[1] for x in y_pred_prod]\n",
    "#         sgd_auc = roc_auc_score(y_test,y_pred_prod)\n",
    "    except:\n",
    "        print('error in SGDClassifier')\n",
    "    \n",
    "#DecisionTreeClassifier.\n",
    "        \n",
    "    try:\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        dt=DecisionTreeClassifier(criterion='gini',random_state=1)\n",
    "        dt.fit(X_train,y_train)\n",
    "        pred=dt.predict(X_test)\n",
    "        # Find Accuracy using accuracy_score method\n",
    "        dt_accuracy =accuracy_score(y_test, pred)\n",
    "        #confusionmatrix=confusion_matrix(y_test,pred) \n",
    "        # Precison\n",
    "        Precision = precision_score(y_test, pred, average='weighted')\n",
    "        # Recall\n",
    "        Recall = recall_score(y_test, pred, average='weighted')\n",
    "        # F1 Score\n",
    "        dt_F1_Score =f1_score(y_test, pred, average='weighted')\n",
    "        # Area Under Curve\n",
    "#         y_pred_prod = dt.predict_proba(X_test)\n",
    "#         y_pred_prod = [x[1] for x in y_pred_prod]\n",
    "#         dt_auc = roc_auc_score(y_test,y_pred_prod)\n",
    "    except:\n",
    "        print('error in DecisionTreeClassifier')\n",
    "        \n",
    "#RandomForestClassifier.\n",
    "        \n",
    "    try:\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        rf=RandomForestClassifier(criterion = 'entropy',random_state=1)\n",
    "        rf=rf.fit(X_train,y_train)\n",
    "        pred=rf.predict(X_test)\n",
    "        # Find Accuracy using accuracy_score method\n",
    "        rf_accuracy = accuracy_score(y_test, pred)\n",
    "        # Precison\n",
    "        Precision = precision_score(y_test, pred, average='weighted')\n",
    "        # Recall\n",
    "        Recall = recall_score(y_test, pred, average='weighted')\n",
    "        # F1 Score\n",
    "        rf_F1_Score =f1_score(y_test, pred, average='weighted')\n",
    "        # Area Under Curve\n",
    "#         y_pred_prod = rf.predict_proba(X_test)\n",
    "#         y_pred_prod = [x[1] for x in y_pred_prod]\n",
    "#         rf_auc = roc_auc_score(y_test,y_pred_prod)\n",
    "    except:\n",
    "        print('error in RandomForestClassifier')\n",
    "        \n",
    "#AdaBoostRegressor\n",
    "    try:\n",
    "        from sklearn.ensemble import AdaBoostRegressor\n",
    "        ada=AdaBoostRegressor()\n",
    "        ada.fit(X_train,y_train)\n",
    "        pred=ada.predict(X_test)\n",
    "        # Find Accuracy using accuracy_score method\n",
    "        ada_accuracy =mean_squared_error(y_test, pred)\n",
    "        # F1 Score\n",
    "        ada_F1_Score =r2_score(y_test, pred)\n",
    "        # Area Under Curve\n",
    "        ada_auc = mean_absolute_error(y_test,pred)\n",
    "    except:\n",
    "        print('error in AdaBoostRegressor')\n",
    "    \n",
    "#GradientBoostingRegressor\n",
    "    try:\n",
    "        from sklearn.ensemble import GradientBoostingRegressor\n",
    "        gbr=GradientBoostingRegressor()\n",
    "        gbr.fit(X_train,y_train)\n",
    "        pred=gb.predict(X_test)\n",
    "        # Find Accuracy using accuracy_score method\n",
    "        gbr_accuracy =mean_squared_error(y_test, pred)\n",
    "        # F1 Score\n",
    "        gbr_F1_Score =r2_score(y_test, pred)\n",
    "        # Area Under Curve\n",
    "        gbr_auc = mean_absolute_error(y_test,pred)\n",
    "    except:\n",
    "        print('error in GradientBoostingRegressor')\n",
    "    \n",
    "        \n",
    "#KNeighborsClassifier\n",
    "    \n",
    "    try:\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "        knn=KNeighborsClassifier( n_neighbors=5,p=2) #p=2 means euclidean distance\n",
    "        knn.fit(X_train,y_train)\n",
    "        pred=knn.predict(X_test)\n",
    "        # Find Accuracy using accuracy_score method\n",
    "        knn_accuracy = accuracy_score(y_test, pred) \n",
    "        # Precison\n",
    "        Precision = precision_score(y_test, pred, average='weighted')\n",
    "        # Recall\n",
    "        Recall = recall_score(y_test, pred, average='weighted')\n",
    "        # F1 Score\n",
    "        knn_F1_Score =f1_score(y_test, pred, average='weighted')\n",
    "        # Area Under Curve\n",
    "#         y_pred_prod = knn.predict_proba(X_test)\n",
    "#         y_pred_prod = [x[1] for x in y_pred_prod]\n",
    "#         knn_auc = roc_auc_score(y_test,y_pred_prod)\n",
    "    except:\n",
    "        print('error in KNeighborsClassifier')\n",
    "    \n",
    "#SVC\n",
    "#     try:\n",
    "#         from sklearn.svm import SVC\n",
    "#         SVC=SVC(random_state=1, kernel='rbf')\n",
    "#         SVC.fit(X_train,y_train)\n",
    "#         pred=SVC.predict(X_test)\n",
    "#         # Find Accuracy using accuracy_score method\n",
    "#         svc_accuracy = accuracy_score(y_test, pred)\n",
    "#         # Precison\n",
    "#         Precision = precision_score(y_test, pred, average='micro')\n",
    "#         # Recall\n",
    "#         Recall = recall_score(y_test, pred, average='micro')\n",
    "#         # F1 Score\n",
    "#         svc_F1_Score =f1_score(y_test, pred, average='micro')\n",
    "#         # Area Under Curve\n",
    "#         #y_pred_prod = SVC.predict_proba(X_test)\n",
    "#         #y_pred_prod = [x[1] for x in y_pred_prod]\n",
    "#         svc_auc = roc_auc_score(y_test,pred)\n",
    "#     except:\n",
    "#         print('error in svc')\n",
    "    \n",
    "#naive_bayes\n",
    "    try:\n",
    "        from sklearn.naive_bayes import GaussianNB\n",
    "        nb=GaussianNB()\n",
    "        nb.fit(X_train,y_train)\n",
    "        pred=nb.predict(X_test)\n",
    "        # Find Accuracy using accuracy_score method\n",
    "        nb_accuracy =accuracy_score(y_test, pred)\n",
    "            # Precison\n",
    "        Precision = precision_score(y_test, pred, average='weighted')\n",
    "        # Recall\n",
    "        Recall = recall_score(y_test, pred, average='weighted')\n",
    "        # F1 Score\n",
    "        nb_F1_Score =f1_score(y_test, pred, average='weighted')\n",
    "        # Area Under Curve\n",
    "#         y_pred_prod = nb.predict_proba(X_test)\n",
    "#         y_pred_prod = [x[1] for x in y_pred_prod]\n",
    "#         nb_auc = roc_auc_score(y_test,y_pred_prod)\n",
    "    except:\n",
    "        print('error in naive_bayes')\n",
    "    \n",
    "#XGBClassifier\n",
    "    try:\n",
    "        from xgboost import XGBClassifier\n",
    "        xgb = XGBClassifier(criterion='gini',max_depth=5, n_estimators=50)\n",
    "        xgb.fit(X_train, y_train)\n",
    "        pred=xgb.predict(X_test)\n",
    "        # Find Accuracy using accuracy_score method\n",
    "        xgb_accuracy = accuracy_score(y_test, pred) \n",
    "        # Precison\n",
    "        Precision = precision_score(y_test, pred, average='weighted')\n",
    "        # Recall\n",
    "        Recall = recall_score(y_test, pred, average='weighted')\n",
    "        # F1 Score\n",
    "        xgb_F1_Score =f1_score(y_test, pred, average='weighted')\n",
    "        # Area Under Curve\n",
    "#         y_pred_prod = xgb.predict_proba(X_test)\n",
    "#         y_pred_prod = [x[1] for x in y_pred_prod]\n",
    "#         xgb_auc = roc_auc_score(y_test,y_pred_prod)\n",
    "    except:\n",
    "        print('error in XGBClassifier')\n",
    "        \n",
    "#CatBoostClassifier\n",
    "    try:\n",
    "        from catboost import CatBoostClassifier\n",
    "        cb = CatBoostClassifier()\n",
    "        cb.fit(X_train, y_train)\n",
    "        pred=cb.predict(X_test)\n",
    "        # Find Accuracy using accuracy_score method\n",
    "        cb_accuracy = accuracy_score(y_test, pred) \n",
    "        # Precison\n",
    "        Precision = precision_score(y_test, pred, average='weighted')\n",
    "        # Recall\n",
    "        Recall = recall_score(y_test, pred, average='weighted')\n",
    "        # F1 Score\n",
    "        cb_F1_Score =f1_score(y_test, pred, average='weighted')\n",
    "        # Area Under Curve\n",
    "#         y_pred_prod = cb.predict_proba(X_test)\n",
    "#         y_pred_prod = [x[1] for x in y_pred_prod]\n",
    "#         cb_auc = roc_auc_score(y_test,y_pred_prod)\n",
    "    except:\n",
    "        print('error in CatBoostClassifier')\n",
    "        \n",
    "#LGBMClassifier\n",
    "    try:\n",
    "        from lightgbm import LGBMClassifier\n",
    "        lgbm = LGBMClassifier()\n",
    "        lgbm.fit(X_train, y_train)\n",
    "        pred=lgbm.predict(X_test)\n",
    "        # Find Accuracy using accuracy_score method\n",
    "        lgbm_accuracy = accuracy_score(y_test, pred) \n",
    "        # Precison\n",
    "        Precision = precision_score(y_test, pred, average='weighted')\n",
    "        # Recall\n",
    "        Recall = recall_score(y_test, pred, average='weighted')\n",
    "        # F1 Score\n",
    "        lgbm_F1_Score =f1_score(y_test, pred, average='weighted')\n",
    "        # Area Under Curve\n",
    "#         y_pred_prod = lgbm.predict_proba(X_test)\n",
    "#         y_pred_prod = [x[1] for x in y_pred_prod]\n",
    "#         lgbm_auc = roc_auc_score(y_test,y_pred_prod)\n",
    "    except:\n",
    "        print('error in LGBMClassifier')\n",
    "    \n",
    "    \n",
    "    Model_Comparison = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'K-Nearest Neighbor', 'Decision Tree', 'Random Forest','Adaboost Classifier','Gradientboost Classifier','SGDClassifier','Naive Bayes','XGBClassifier','CatBoostClassifier','LGBMClassifier'],\n",
    "    'Accuracy': [logmodel_accuracy, knn_accuracy,dt_accuracy, rf_accuracy, ada_accuracy,gbr_accuracy, nb_accuracy, sgd_accuracy, xgb_accuracy,cb_accuracy,lgbm_accuracy],\n",
    "    #'roc_auc_score': [logmodel_auc, svc_auc, knn_auc, dt_auc, rf_auc, nb_auc, sgd_auc, xgb_auc,cb_auc,lgbm_auc],\n",
    "    'F1_score':[logmodel_F1_Score, knn_F1_Score, dt_F1_Score, rf_F1_Score,ada_F1_Score,gbr_F1_Score, sgd_F1_Score, nb_F1_Score, xgb_F1_Score,cb_F1_Score,lgbm_F1_Score]})\n",
    "\n",
    "    Model_Comparison_df = Model_Comparison.sort_values(by='F1_score', ascending=False)\n",
    "    Model_Comparison_df = Model_Comparison_df.set_index('Model')\n",
    "    print(Model_Comparison_df.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6fb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "training(X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130aba51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b872de51",
   "metadata": {},
   "source": [
    "# Classification in the form of function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d92f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from   sklearn.metrics import confusion_matrix , classification_report, accuracy_score, roc_auc_score, plot_roc_curve,precision_score,recall_score,f1_score\n",
    "\n",
    "from   sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from   sklearn.tree import DecisionTreeClassifier\n",
    "from   sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier, GradientBoostingClassifier\n",
    "from   sklearn.neighbors import KNeighborsClassifier\n",
    "from   sklearn.svm import SVC\n",
    "from   sklearn.naive_bayes import GaussianNB\n",
    "from   xgboost import XGBClassifier\n",
    "from   lightgbm import LGBMClassifier\n",
    "from   catboost import CatBoostClassifier\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ddcffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = [LogisticRegression(), SGDClassifier(), DecisionTreeClassifier(), RandomForestClassifier(), AdaBoostClassifier(), GradientBoostingClassifier(), KNeighborsClassifier(), GaussianNB(), XGBClassifier(),LGBMClassifier(),CatBoostClassifier()]\n",
    "model = [LogisticRegression(), SGDClassifier(), DecisionTreeClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b92f7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "def training(models, X_train,X_test,y_train,y_test):\n",
    "    for mod in models:\n",
    "        try :\n",
    "            start = time.time()\n",
    "            mod.fit(X_train,y_train)\n",
    "            pred = mod.predict(X_test)\n",
    "            # Find Accuracy using accuracy_score method\n",
    "            accuracy = accuracy_score(y_test, pred)\n",
    "            # Precison\n",
    "            Precision = precision_score(y_test, pred, average='weighted')\n",
    "            # Recall\n",
    "            Recall = recall_score(y_test, pred, average='weighted')\n",
    "            # F1 Score\n",
    "            F1_Score =f1_score(y_test, pred, average='weighted')\n",
    "            # Area Under Curve\n",
    "    #         y_pred_prod = logmodel.predict_proba(X_test)\n",
    "    #         y_pred_prod = [x[1] for x in y_pred_prod]\n",
    "    #         auc_roc = roc_auc_score(y_test,y_pred_prod)\n",
    "\n",
    "            results.append({'Model' : str(mod),\n",
    "                            'Accuracy': accuracy,\n",
    "                            'Precision': Precision,\n",
    "                            'Recall': Recall,\n",
    "                            'F1_Score': F1_Score\n",
    "        #                         'auc_roc' : auc_roc\n",
    "                            })\n",
    "            end = time.time()\n",
    "            print('for training' ,mod, 'is',round(end-start),'sec' )\n",
    "        except:\n",
    "            print('error in training',mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c1cd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "training(all_models, X_train,X_test,y_train,y_test)\n",
    "pd.DataFrame(results).sort_values(by='F1_Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0bf855",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fafc55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
